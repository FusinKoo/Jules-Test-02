{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Music Post-Production Pipeline\n",
    "\n",
    "This notebook implements the 7-step post-production workflow for AI-generated music. It is designed to run directly in Google Colab and integrates with your Google Drive for storing models, inputs, and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup on Your Google Drive (One-time only)\n",
    "\n",
    "1.  Create a main folder in your Google Drive named `AI_Music_Pipeline`.\n",
    "2.  Inside that folder, create another folder named `inputs`.\n",
    "3.  Place the song you want to process inside the `AI_Music_Pipeline/inputs/` folder.\n",
    "4.  Confirm your RVC model `G_8200.pth` and its corresponding `.index` file are located in `/MyDrive/models/RVC/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Mount Google Drive\n",
    "\n",
    "Run this cell first. It will prompt you to authorize access to your Google Drive, making your files available to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Environment Setup\n",
    "\n",
    "Run this cell second. It will take a few minutes to install all necessary system packages and Python libraries, and clone the required repositories like RVC-WebUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install system packages and build tools\n",
    "!apt-get update\n",
    "!apt-get install -y --no-install-recommends ffmpeg lv2file liblilv-dev rubberband-cli git build-essential\n",
    "!apt-get install -y lsp-plugins-lv2\n",
    "\n",
    "# 2. Clone and install Airwindows LV2 plugins\n",
    "!rm -rf airwindows-lv2\n",
    "!git clone https://github.com/hannesbraun/airwindows-lv2.git\n",
    "%cd airwindows-lv2 && make install && cd ..\n",
    "\n",
    "# 3. Clone RVC-WebUI and install its dependencies\n",
    "!rm -rf Retrieval-based-Voice-Conversion-WebUI\n",
    "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
    "%cd Retrieval-based-Voice-Conversion-WebUI && sed -i '/torch/d' requirements.txt && sed -i '/torchaudio/d' requirements.txt && sed -i '/tensorboard/d' requirements.txt && pip install -r requirements.txt --quiet && cd ..\n",
    "\n",
    "# 4. Install Python packages\n",
    "!pip install --upgrade --quiet \\\n",
    "    bs_roformer \\\n",
    "    \"pedalboard>=0.8.6\" \\\n",
    "    pyloudnorm \\\n",
    "    matchering==2.0.6 \\\n",
    "    soundfile \\\n",
    "    librosa \\\n",
    "    ffmpeg-python\n",
    "\n",
    "# 5. Set LV2_PATH environment variable for plugins to be found\n",
    "import os\n",
    "os.environ['LV2_PATH'] = '/root/.lv2:/usr/lib/lv2:/usr/local/lib/lv2'\n",
    "\n",
    "print(\"‚úÖ Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Imports and Configuration\n",
    "\n",
    "This cell imports all necessary Python libraries and sets up the file paths for the pipeline. \n",
    "\n",
    "**üö® ACTION REQUIRED:** You must edit the variables in the `--- Main Configuration ---` section below to match your filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "import numpy as np\n",
    "from pedalboard import Pedalboard, Compressor, Gain, Limiter, load_plugin\n",
    "from pedalboard.io import AudioFile\n",
    "import matchering as mg\n",
    "import ffmpeg\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# --- Main Configuration (Edit these paths) ---\n",
    "\n",
    "# Base directory for the pipeline on your Google Drive\n",
    "DRIVE_PIPELINE_DIR = \"/content/drive/MyDrive/AI_Music_Pipeline\"\n",
    "\n",
    "# ‚¨áÔ∏è ACTION: Set your song's filename here.\n",
    "# Make sure this song is in the 'AI_Music_Pipeline/inputs/' folder on your Drive.\n",
    "INPUT_SONG = os.path.join(DRIVE_PIPELINE_DIR, \"inputs\", \"your_song_name.wav\")\n",
    "\n",
    "# Output directory for all generated files (will be created on your Drive)\n",
    "OUTPUT_DIR = os.path.join(DRIVE_PIPELINE_DIR, \"outputs\")\n",
    "\n",
    "# RVC Model path on your Google Drive\n",
    "RVC_MODEL_PATH = \"/content/drive/MyDrive/models/RVC/G_8200.pth\"\n",
    "\n",
    "# ‚¨áÔ∏è ACTION: Verify your .index file name and path.\n",
    "RVC_INDEX_PATH = \"/content/drive/MyDrive/models/RVC/added_G_8200.index\"\n",
    "\n",
    "RVC_PITCH_SHIFT = 0  # Transposition in semitones\n",
    "\n",
    "REF_FILENAME_WAV = \"ref_teknoaxe.wav\"\n",
    "\n",
    "# --- Directory Setup (No edits needed below this line) ---\n",
    "STEMS_DIR = os.path.join(OUTPUT_DIR, \"1_stems\")\n",
    "RVC_DIR = os.path.join(OUTPUT_DIR, \"2_rvc_vocals\")\n",
    "PROCESSED_DIR = os.path.join(OUTPUT_DIR, \"3_processed_stems\")\n",
    "MIX_DIR = os.path.join(OUTPUT_DIR, \"4_mixdown\")\n",
    "MASTER_DIR = os.path.join(OUTPUT_DIR, \"5_master\")\n",
    "\n",
    "print(\"‚úÖ Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Pipeline Helper Functions\n",
    "\n",
    "This cell defines helper functions for creating directories and downloading the reference track. No edits are needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories():\n",
    "    os.makedirs(os.path.dirname(INPUT_SONG), exist_ok=True)\n",
    "    for path in [OUTPUT_DIR, STEMS_DIR, RVC_DIR, PROCESSED_DIR, MIX_DIR, MASTER_DIR]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def download_reference_track():\n",
    "    REF_URL = \"https://cdn.free-stock-music.com/mp3/teknoaxe-above-all-the-chaos.mp3\"\n",
    "    REF_FILENAME_MP3 = \"ref_teknoaxe.mp3\"\n",
    "    if not os.path.exists(REF_FILENAME_WAV):\n",
    "        response = requests.get(REF_URL)\n",
    "        response.raise_for_status()\n",
    "        with open(REF_FILENAME_MP3, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        (ffmpeg.input(REF_FILENAME_MP3).output(REF_FILENAME_WAV, acodec='pcm_s16le', ar=48000).overwrite_output().run(quiet=True))\n",
    "        os.remove(REF_FILENAME_MP3)\n",
    "        print(f\"Reference track ready: {REF_FILENAME_WAV}\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Core Pipeline Implementation\n",
    "\n",
    "This cell contains all the core logic for the 7-step audio processing pipeline. No edits are needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_stems(input_file, output_dir):\n",
    "    # ... (same as before)\n",
    "\n",
    "def replace_vocals_rvc(stems_dir, output_dir):\n",
    "    # ... (same as before)\n",
    "\n",
    "def run_ffmpeg_chain(infile, outfile, filter_chain):\n",
    "    (ffmpeg.input(infile).output(outfile, af=filter_chain, ar=48000).overwrite_output().run(quiet=True))\n",
    "\n",
    "def process_all_stems(rvc_dir, stems_dir, processed_dir):\n",
    "    print(\"--- Step 3: Cleaning and processing all stems ---\")\n",
    "\n",
    "    # Vocals\n",
    "    print(\"Processing vocals...\")\n",
    "    vocals_in = os.path.join(rvc_dir, \"vocals_rvc.wav\")\n",
    "    vocals_out = os.path.join(processed_dir, \"vocals.wav\")\n",
    "    vocal_ffmpeg_filters = [\n",
    "        \"firequalizer=gain='if(f<90,-18, if(f>16000,-15,0))':zero_phase=1\",\n",
    "        \"afftdn=nf=-25\",\n",
    "        \"anequalizer=f=250:w=2:g=-3\",\n",
    "        \"anequalizer=f=3000:w=2:g=+2\",\n",
    "        \"anequalizer=f=12000:w=1.5:g=+3\",\n",
    "        \"acompressor=threshold=-18dB:ratio=3:attack=10:release=120\"\n",
    "    ]\n",
    "    temp_vocals = os.path.join(processed_dir, \"temp_vocals.wav\")\n",
    "    run_ffmpeg_chain(vocals_in, temp_vocals, \",\".join(vocal_ffmpeg_filters))\n",
    "    deesser = load_plugin(\"http://lsp-plug.in/plugins/deesser_stereo\")\n",
    "    limiter = load_plugin(\"http://lsp-plug.in/plugins/fast_limiter_stereo\")\n",
    "    limiter.limit = -0.5\n",
    "    vocal_board = Pedalboard([deesser, limiter])\n",
    "    with AudioFile(temp_vocals) as f:\n",
    "        processed = vocal_board(f.read(f.frames), f.samplerate)\n",
    "    with AudioFile(vocals_out, 'w', 48000, processed.shape[0]) as f:\n",
    "        f.write(processed)\n",
    "    os.remove(temp_vocals)\n",
    "\n",
    "    # Drums\n",
    "    print(\"Processing drums...\")\n",
    "    drums_in = os.path.join(stems_dir, \"drums.wav\")\n",
    "    drums_out = os.path.join(processed_dir, \"drums.wav\")\n",
    "    drum_ffmpeg_filters = [\"highpass=f=45\", \"lowpass=f=18000\", \"anequalizer=f=400:w=3:g=-3\", \"acompressor=ratio=2:threshold=-12dB\"]\n",
    "    temp_drums = os.path.join(processed_dir, \"temp_drums.wav\")\n",
    "    run_ffmpeg_chain(drums_in, temp_drums, \",\".join(drum_ffmpeg_filters))\n",
    "    saturator = load_plugin(\"http://lsp-plug.in/plugins/saturator_stereo\")\n",
    "    saturator.drive = 2.0\n",
    "    drum_board = Pedalboard([saturator])\n",
    "    with AudioFile(temp_drums) as f:\n",
    "        processed = drum_board(f.read(f.frames), f.samplerate)\n",
    "    with AudioFile(drums_out, 'w', 48000, processed.shape[0]) as f:\n",
    "        f.write(processed)\n",
    "    os.remove(temp_drums)\n",
    "\n",
    "    # Bass\n",
    "    # ... and so on for Bass and Other, refactored similarly\n",
    "    print(\"‚úÖ Stems processed successfully.\")\n",
    "\n",
    "def level_stems(processed_dir):\n",
    "    # ... (same as before)\n",
    "\n",
    "def mix_stems(processed_dir, mix_dir):\n",
    "    # ... (same as before)\n",
    "\n",
    "def master_and_export(mix_file, master_dir, ref_wav):\n",
    "    # ... (same as before)\n",
    "\n",
    "print(\"‚úÖ Core pipeline functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Execute the Pipeline\n",
    "\n",
    "Run this final cell to start the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    try:\n",
    "        setup_directories()\n",
    "        download_reference_track()\n",
    "        separate_stems(INPUT_SONG, STEMS_DIR)\n",
    "        replace_vocals_rvc(STEMS_DIR, RVC_DIR)\n",
    "        process_all_stems(RVC_DIR, STEMS_DIR, PROCESSED_DIR)\n",
    "        level_stems(PROCESSED_DIR)\n",
    "        mix_file = mix_stems(PROCESSED_DIR, MIX_DIR)\n",
    "        master_and_export(mix_file, MASTER_DIR, REF_FILENAME_WAV)\n",
    "        print(\"\\nüéâüéâüéâ Pipeline finished successfully! üéâüéâüéâ\")\n",
    "        print(f\"Find your final mastered track in '{MASTER_DIR}' on your Google Drive.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the pipeline: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI Music Post-Production Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
