{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Music Post-Production Pipeline\n",
    "\n",
    "This notebook implements the 7-step post-production workflow for AI-generated music. It is designed to run directly in Google Colab and integrates with your Google Drive for storing models, inputs, and outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup on Your Google Drive (One-time only)\n",
    "\n",
    "1.  Create a main folder in your Google Drive named `AI_Music_Pipeline`.\n",
    "2.  Inside that folder, create another folder named `inputs`.\n",
    "3.  Place the song you want to process inside the `AI_Music_Pipeline/inputs/` folder.\n",
    "4.  Confirm your RVC model `G_8200.pth` and its corresponding `.index` file are located in `/MyDrive/models/RVC/`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Mount Google Drive\n",
    "\n",
    "Run this cell first. It will prompt you to authorize access to your Google Drive, making your files available to this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Environment Setup\n",
    "\n",
    "Run this cell second. It will take a few minutes to install all necessary system packages and Python libraries, and clone the required repositories like RVC-WebUI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0. Upgrade packaging tools\\n",
    "!pip install --upgrade pip==24.0 setuptools wheel\\n",
    "\\n",
    "# 1. Install system packages and build tools\n",
    "!apt-get update\n",
    "!apt-get install -y --no-install-recommends ffmpeg lv2file liblilv-dev rubberband-cli git build-essential\n",
    "!apt-get install -y lsp-plugins-lv2\n",
    "\n",
    "# 2. Clone and install Airwindows LV2 plugins\n",
    "!rm -rf airwindows-lv2\n",
    "!git clone https://github.com/hannesbraun/airwindows-lv2.git\n",
    "%cd airwindows-lv2\n",
    "!make install\n",
    "%cd ..\n",
    "\n",
    "# 3. Clone RVC-WebUI and install its dependencies\n",
    "!rm -rf Retrieval-based-Voice-Conversion-WebUI\n",
    "!git clone https://github.com/RVC-Project/Retrieval-based-Voice-Conversion-WebUI.git\n",
    "%cd Retrieval-based-Voice-Conversion-WebUI\n",
    "!sed -i '/torch/d' requirements.txt\n",
    "!sed -i '/torchaudio/d' requirements.txt\n",
    "!sed -i '/tensorboard/d' requirements.txt\n",
    "!pip install -r requirements.txt --quiet\n",
    "%cd ..\n",
    "\n",
    "# 4. Install Python packages\n",
    "!pip install --upgrade --quiet --break-system-packages \\\n",
    "    BS-RoFormer \\\n",
    "    \"pedalboard>=0.8.6\" \\\n",
    "    pyloudnorm \\\n",
    "    matchering==2.0.6 \\\n",
    "    soundfile \\\n",
    "    librosa \\\n",
    "    ffmpeg-python\n",
    "\n",
    "# 5. Set LV2_PATH environment variable for plugins to be found\n",
    "import os\n",
    "os.environ['LV2_PATH'] = '/root/.lv2:/usr/lib/lv2:/usr/local/lib/lv2'\n",
    "\n",
    "print(\"‚úÖ Environment setup complete.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Imports and Configuration\n",
    "\n",
    "This cell imports all necessary Python libraries and sets up the file paths for the pipeline. \n",
    "\n",
    "**üö® ACTION REQUIRED:** You must edit the variables in the `--- Main Configuration ---` section below to match your filenames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import soundfile as sf\n",
    "import pyloudnorm as pyln\n",
    "import numpy as np\n",
    "from pedalboard import Pedalboard, Compressor, Gain, Limiter, load_plugin\n",
    "from pedalboard.io import AudioFile\n",
    "import matchering as mg\n",
    "import ffmpeg\n",
    "import requests\n",
    "import shutil\n",
    "\n",
    "# --- Main Configuration (Edit these paths) ---\n",
    "\n",
    "DRIVE_PIPELINE_DIR = \"/content/drive/MyDrive/AI_Music_Pipeline\"\n",
    "INPUTS_DIR = os.path.join(DRIVE_PIPELINE_DIR, \"inputs\")\n",
    "OUTPUT_DIR = os.path.join(DRIVE_PIPELINE_DIR, \"outputs\")\n",
    "RVC_MODEL_PATH = \"/content/drive/MyDrive/models/RVC/G_8200.pth\"\n",
    "RVC_INDEX_PATH = \"/content/drive/MyDrive/models/RVC/added_G_8200.index\"\n",
    "RVC_PITCH_SHIFT = 0\n",
    "REF_FILENAME_WAV = \"ref_music.wav\"\n",
    "\n",
    "# --- Directory Setup (No edits needed below this line) ---\n",
    "STEMS_DIR = os.path.join(OUTPUT_DIR, \"1_stems\")\n",
    "RVC_DIR = os.path.join(OUTPUT_DIR, \"2_rvc_vocals\")\n",
    "PROCESSED_DIR = os.path.join(OUTPUT_DIR, \"3_processed_stems\")\n",
    "MIX_DIR = os.path.join(OUTPUT_DIR, \"4_mixdown\")\n",
    "MASTER_DIR = os.path.join(OUTPUT_DIR, \"5_master\")\n",
    "\n",
    "print(\"‚úÖ Configuration loaded.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Pipeline Helper Functions\n",
    "\n",
    "This cell defines helper functions for creating directories and downloading the reference track. No edits are needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_directories():\n",
"    # Also create the main input directory if it doesn't exist\n",
"    os.makedirs(INPUTS_DIR, exist_ok=True)\n",
"    # Create a directory to move completed source files to\n",
"    COMPLETED_DIR = os.path.join(OUTPUT_DIR, \"completed_sources\")\n",
"    for path in [OUTPUT_DIR, STEMS_DIR, RVC_DIR, PROCESSED_DIR, MIX_DIR, MASTER_DIR, COMPLETED_DIR]:\n",
    "        os.makedirs(path, exist_ok=True)\n",
    "\n",
    "def download_reference_track():\n",
    "    drive_ref_path = os.path.join(DRIVE_PIPELINE_DIR, \"inputs\", \"ref_music.wav\")\n",
    "    local_ref_path = \"ref_music.wav\"\n",
    "    if not os.path.exists(drive_ref_path):\n",
    "        raise FileNotFoundError(f\"Reference file not found at {drive_ref_path}. Please upload 'ref_music.wav' to the 'AI_Music_Pipeline/inputs' folder on your Google Drive.\")\n",
    "    print(f\"Copying reference track from {drive_ref_path} to {local_ref_path}\")\n",
    "    shutil.copy(drive_ref_path, local_ref_path)\n",
    "    print(f\"Reference track ready: {local_ref_path}\")\n",
    "\n",
"def check_environment():\n",
    "    \"\"\"Checks if all required command-line tools are available.\"\"\"\n",
    "    print(\"Checking for required tools...\")\n",
    "    if not shutil.which(\"bs_roformer\"):\n",
    "        raise FileNotFoundError(\"The 'bs_roformer' command was not found. This means the environment is not set up correctly. Please run Cell 2 (Environment Setup) and wait for it to complete before running the pipeline.\")\n",
    "    print(\"‚úÖ All required tools found.\")\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: Core Pipeline Implementation\n",
    "\n",
    "This cell contains all the core logic for the 7-step audio processing pipeline. No edits are needed here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_stems(input_file, output_dir):\n",
    "    print(\"--- Step 1: Separating audio into 4 stems with BS-RoFormer ---\")\n",
    "    if not os.path.exists(input_file):\n",
    "        raise FileNotFoundError(f\"Input song '{input_file}' not found. Please make sure it's in the 'inputs' folder on your Drive and the filename is correct.\")\n",
    "    cmd = [\"bs_roformer\", \"--input\", input_file, \"--output_dir\", output_dir, \"--model_type\", \"bs_roformer_hq_ep_300\"]\n",
    "    subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "    print(\"‚úÖ Stems separated successfully.\")\n",
    "\n",
    "def replace_vocals_rvc(stems_dir, output_dir):\n",
    "    print(\"--- Step 2: Replacing vocals using RVC ---\")\n",
    "    vocals_in = os.path.join(stems_dir, \"vocals.wav\")\n",
    "    vocals_out = os.path.join(output_dir, \"vocals_rvc.wav\")\n",
    "    if not os.path.exists(RVC_MODEL_PATH) or not os.path.exists(RVC_INDEX_PATH):\n",
    "        print(f\"‚ö†Ô∏è RVC model or index file not found on your Google Drive. Skipping vocal replacement. Searched for {RVC_MODEL_PATH} and {RVC_INDEX_PATH}\")\n",
    "        shutil.copy(vocals_in, vocals_out)\n",
    "        return\n",
    "    rvc_script = \"/content/RVC-WebUI/tools/infer_cli.py\"\n",
    "    cmd = [\"python\", rvc_script, \"--f0up_key\", str(RVC_PITCH_SHIFT), \"--input_path\", vocals_in, \"--index_path\", RVC_INDEX_PATH, \"--f0method\", \"rmvpe\", \"--model_path\", RVC_MODEL_PATH, \"--output_path\", vocals_out, \"--index_rate\", \"0.75\", \"--filter_radius\", \"3\", \"--resample_sr\", \"48000\", \"--rms_mix_rate\", \"0.25\", \"--protect\", \"0.33\"]\n",
    "    print(\"Executing RVC inference...\")\n",
    "    result = subprocess.run(cmd, check=True, capture_output=True, text=True)\n",
    "    print(result.stdout)\n",
    "    print(result.stderr)\n",
    "    print(\"‚úÖ Vocal replacement successful.\")\n",
    "\n",
    "def run_ffmpeg_chain(infile, outfile, filter_chain_list):\n",
    "    filter_chain_str = \",\".join(filter_chain_list)\n",
    "    (ffmpeg.input(infile).output(outfile, af=filter_chain_str, ar=48000).overwrite_output().run(quiet=True))\n",
    "\n",
    "def process_all_stems(rvc_dir, stems_dir, processed_dir):\n",
    "    print(\"--- Step 3: Cleaning and processing all stems ---\")\n",
    "    \n",
    "    # Vocals\n",
    "    print(\"Processing vocals...\")\n",
    "    vocals_in = os.path.join(rvc_dir, \"vocals_rvc.wav\")\n",
    "    vocals_out = os.path.join(processed_dir, \"vocals.wav\")\n",
    "    vocal_ffmpeg_filters = [\n",
    "        \"firequalizer=gain='if(f<90,-18, if(f>16000,-15,0))':zero_phase=1\",\n",
    "        \"afftdn=nf=-25\",\n",
    "        \"anequalizer=f=250:w=2:g=-3\",\n",
    "        \"anequalizer=f=3000:w=2:g=+2\",\n",
    "        \"anequalizer=f=12000:w=1.5:g=+3\",\n",
    "        \"acompressor=threshold=-18dB:ratio=3:attack=10:release=120\"\n",
    "    ]\n",
    "    temp_vocals = os.path.join(processed_dir, \"temp_vocals.wav\")\n",
    "    run_ffmpeg_chain(vocals_in, temp_vocals, vocal_ffmpeg_filters)\n",
    "    deesser = load_plugin(\"http://lsp-plug.in/plugins/deesser_stereo\")\n",
    "    limiter = load_plugin(\"http://lsp-plug.in/plugins/fast_limiter_stereo\")\n",
    "    limiter.limit = -0.5\n",
    "    vocal_board = Pedalboard([deesser, limiter])\n",
    "    with AudioFile(temp_vocals, 'r') as f:\n",
    "        with AudioFile(vocals_out, 'w', f.samplerate, f.num_channels) as o:\n",
    "            o.write(vocal_board(f.read(f.frames)))\n",
    "    os.remove(temp_vocals)\n",
    "\n",
    "    # Drums\n",
    "    print(\"Processing drums...\")\n",
    "    drums_in = os.path.join(stems_dir, \"drums.wav\")\n",
    "    drums_out = os.path.join(processed_dir, \"drums.wav\")\n",
    "    drum_ffmpeg_filters = [\"highpass=f=45\", \"lowpass=f=18000\", \"anequalizer=f=400:w=3:g=-3\", \"acompressor=ratio=2:threshold=-12dB\"]\n",
    "    temp_drums = os.path.join(processed_dir, \"temp_drums.wav\")\n",
    "    run_ffmpeg_chain(drums_in, temp_drums, drum_ffmpeg_filters)\n",
    "    saturator = load_plugin(\"http://lsp-plug.in/plugins/saturator_stereo\")\n",
    "    saturator.drive = 2.0\n",
    "    drum_board = Pedalboard([saturator])\n",
    "    with AudioFile(temp_drums, 'r') as f:\n",
    "        with AudioFile(drums_out, 'w', f.samplerate, f.num_channels) as o:\n",
    "            o.write(drum_board(f.read(f.frames)))\n",
    "    os.remove(temp_drums)\n",
    "\n",
    "    # Bass\n",
    "    print(\"Processing bass...\")\n",
    "    bass_in = os.path.join(stems_dir, \"bass.wav\")\n",
    "    bass_out = os.path.join(processed_dir, \"bass.wav\")\n",
    "    bass_ffmpeg_filters = [\"highpass=f=30\", \"lowpass=f=8000\", \"acompressor=threshold=-15dB:ratio=4\"]\n",
    "    temp_bass = os.path.join(processed_dir, \"temp_bass.wav\")\n",
    "    run_ffmpeg_chain(bass_in, temp_bass, bass_ffmpeg_filters)\n",
    "    basskit = load_plugin(\"http://hannesbraun.de/plugins/airwindows/BassKit\")\n",
    "    basskit.Boost = 0.3\n",
    "    bass_board = Pedalboard([basskit])\n",
    "    with AudioFile(temp_bass, 'r') as f:\n",
    "        with AudioFile(bass_out, 'w', f.samplerate, f.num_channels) as o:\n",
    "            o.write(bass_board(f.read(f.frames)))\n",
    "    os.remove(temp_bass)\n",
    "\n",
    "    # Other\n",
    "    print(\"Processing 'other' stem...\")\n",
    "    other_in = os.path.join(stems_dir, \"other.wav\")\n",
    "    other_out = os.path.join(processed_dir, \"other.wav\")\n",
    "    other_ffmpeg_filters = [\"highpass=f=110\", \"lowpass=f=16000\", \"anequalizer=f=5000:w=2:g=+2\", \"acompressor=threshold=-14dB:ratio=2\"]\n",
    "    run_ffmpeg_chain(other_in, other_out, other_ffmpeg_filters)\n",
    "    print(\"‚úÖ Stems processed successfully.\")\n",
    "\n",
    "def level_stems(processed_dir):\n",
    "    print(\"--- Step 4: Leveling stems to target LUFS & peak ---\")\n",
    "    stems_to_level = { \"vocals\": {\"target_lufs\": -18.0, \"target_peak\": -6.0}, \"drums\":  {\"target_lufs\": -14.0, \"target_peak\": -3.0}, \"bass\":   {\"target_lufs\": -17.0, \"target_peak\": -5.0}, \"other\":  {\"target_lufs\": -20.0, \"target_peak\": -7.0} }\n",
    "    meter = pyln.Meter(48000)\n",
    "    for name, targets in stems_to_level.items():\n",
    "        filepath = os.path.join(processed_dir, f\"{name}.wav\")\n",
    "        data, rate = sf.read(filepath)\n",
    "        loudness = meter.integrated_loudness(data)\n",
    "        gain_db = targets[\"target_lufs\"] - loudness\n",
    "        board = Pedalboard([Gain(gain_db=gain_db)])\n",
    "        leveled_data = board(data, rate)\n",
    "        peak_linear = np.max(np.abs(leveled_data))\n",
    "        target_peak_linear = 10**(targets[\"target_peak\"] / 20.0)\n",
    "        if peak_linear > target_peak_linear:\n",
    "            leveled_data *= (target_peak_linear / peak_linear)\n",
    "        sf.write(filepath, leveled_data.T, rate)\n",
    "        final_lufs = pyln.Meter(rate).integrated_loudness(leveled_data.T)\n",
    "        final_peak = 20 * np.log10(np.max(np.abs(leveled_data)))\n",
    "        print(f\"  Leveled '{name}': LUFS={final_lufs:.2f}, Peak={final_peak:.2f} dBFS\")\n",
    "    print(\"‚úÖ Stems leveled successfully.\")\n",
    "\n",
    "def mix_stems(processed_dir, mix_dir):\n",
    "    print(\"--- Step 5: Mixing all stems ---\")\n",
    "    stem_files = [os.path.join(processed_dir, f) for f in os.listdir(processed_dir) if f.endswith('.wav')]\n",
    "    stems_audio, max_len, samplerate = [], 0, 48000\n",
    "    for f in stem_files:\n",
    "        with AudioFile(f) as af:\n",
    "            stems_audio.append(af.read(af.frames))\n",
    "            if af.frames > max_len: max_len = af.frames\n",
    "            samplerate = af.samplerate\n",
    "    for i, stem in enumerate(stems_audio):\n",
    "        if stem.shape[1] < max_len:\n",
    "            stems_audio[i] = np.concatenate([stem, np.zeros((stem.shape[0], max_len - stem.shape[1]))], axis=1)\n",
    "    mixdown = np.sum(np.array(stems_audio), axis=0)\n",
    "    peak, target_peak = np.max(np.abs(mixdown)), 10**(-4.0 / 20.0)\n",
    "    if peak > target_peak: mixdown *= (target_peak / peak)\n",
    "    mix_file = os.path.join(mix_dir, \"mixdown.wav\")\n",
    "    with AudioFile(mix_file, 'w', samplerate, mixdown.shape[0]) as f: f.write(mixdown)\n",
    "    print(f\"‚úÖ Mixdown saved to {mix_file}\")\n",
    "    return mix_file\n",
    "\n",
    "def master_and_export(mix_file, master_dir, ref_wav):\n",
    "    print(\"--- Step 6 & 7: Mastering with Matchering and exporting final WAV ---\")\n",
    "    master_file = os.path.join(master_dir, \"master_24bit_48kHz.wav\")\n",
    "    mg.process(target=mix_file, reference=ref_wav, results=[mg.pcm24(master_file)], sample_rate=48000)\n",
    "    data, rate = sf.read(master_file)\n",
    "    meter = pyln.Meter(rate)\n",
    "    loudness = meter.integrated_loudness(data)\n",
    "    peak = 20 * np.log10(np.max(np.abs(data)))\n",
    "    print(\"‚úÖ Mastering complete!\")\n",
    "    print(f\"Final output: {master_file}\")\n",
    "    print(f\"  - Format: 24-bit, {rate} Hz WAV\")\n",
    "    print(f\"  - Integrated Loudness: {loudness:.2f} LUFS (Target: ~-13 LUFS)\")\n",
    "    print(f\"  - Peak: {peak:.2f} dBFS (Target: -1 dBTP)\")\n",
    "\n",
    "print(\"‚úÖ Core pipeline functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: Execute the Pipeline\n",
    "\n",
    "Run this final cell to start the entire process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
"    # --- 1. Find audio files to process ---\n",
"    SUPPORTED_EXTENSIONS = ['.wav', '.mp3', '.flac', '.aiff', '.ogg']\n",
"    audio_files = []\n",
"    for filename in os.listdir(INPUTS_DIR):\n",
"        if any(filename.lower().endswith(ext) for ext in SUPPORTED_EXTENSIONS) and filename != REF_FILENAME_WAV:\n",
"            audio_files.append(os.path.join(INPUTS_DIR, filename))\n",
"\n",
"    if not audio_files:\n",
"        print(f\"No audio files found in {INPUTS_DIR}. Nothing to process.\")\n",
"        return\n",
"\n",
"    print(f\"Found {len(audio_files)} song(s) to process:\")\n",
"    for f in audio_files:\n",
"        print(f\"  - {os.path.basename(f)}\")\n",
"\n",
"    # --- 2. Setup main directories ---\n",
    "    try:\n",
    "        check_environment() # Check for missing tools before we start\n",
    "        setup_directories()\n",
"        download_reference_track()\n",
"        print(\"\\n--- Starting Batch Processing ---\")\n",
"\n",
"        for i, song_path in enumerate(audio_files):\n",
"            song_name = os.path.basename(song_path)\n",
"            print(f\"\\n--- Processing Song {i+1}/{len(audio_files)}: {song_name} ---\")\n",
"\n",
"            # Run the full pipeline for the current song\n",
"            separate_stems(song_path, STEMS_DIR)\n",
"            replace_vocals_rvc(STEMS_DIR, RVC_DIR)\n",
"            process_all_stems(RVC_DIR, STEMS_DIR, PROCESSED_DIR)\n",
"            level_stems(PROCESSED_DIR)\n",
"            mix_file = mix_stems(PROCESSED_DIR, MIX_DIR)\n",
"            master_and_export(mix_file, MASTER_DIR, REF_FILENAME_WAV)\n",
"\n",
            "            # Move the original file to the completed directory\n",
            "            completed_dir = os.path.join(OUTPUT_DIR, \"completed_sources\")\n",
            "            shutil.move(song_path, os.path.join(completed_dir, song_name))\n",
            "            print(f\"Moved '{song_name}' to completed sources directory.\")\n",
"            print(f\"--- Finished processing {song_name} ---\")\n",
"\n",
"        print(\"\\nüéâüéâüéâ Batch processing finished successfully! üéâüéâüéâ\")\n",
    "        print(f\"Find your final mastered track in '{MASTER_DIR}' on your Google Drive.\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå An error occurred during the pipeline: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "AI_Music_Post_Production_Pipeline.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
