{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Environment Setup\n",
    "import os, re, subprocess, sys\n",
    "from pathlib import Path\n",
    "\n",
    "def run(cmd):\n",
    "    print('+', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "try:\n",
    "    run(['apt-get', 'update'])\n",
    "    apt = Path('apt.txt')\n",
    "    if apt.exists():\n",
    "        pkgs = [p.strip() for p in apt.read_text().splitlines() if p.strip()]\n",
    "        if pkgs:\n",
    "            run(['apt-get', 'install', '-y', *pkgs])\n",
    "except Exception as e:\n",
    "    print('Skipping apt-get install:', e)\n",
    "\n",
    "gpu = subprocess.run(['bash','-lc','nvidia-smi'], capture_output=True, text=True)\n",
    "has_gpu = gpu.returncode == 0\n",
    "index = os.environ.get('PYTORCH_INDEX_URL')\n",
    "if not index and has_gpu:\n",
    "    m = re.search(r'CUDA Version: (\\d+)\\.(\\d+)', gpu.stdout or gpu.stderr)\n",
    "    if m:\n",
    "        index = f\"https://download.pytorch.org/whl/cu{m.group(1)}{m.group(2)}\"\n",
    "if not index:\n",
    "    index = \"https://download.pytorch.org/whl/cpu\"\n",
    "print('Using PyTorch index:', index)\n",
    "try:\n",
    "    run([sys.executable, '-m', 'pip', 'install', f'--index-url={index}', 'torch==2.3.0', 'torchvision==0.18.0', 'torchaudio==2.3.0'])\n",
    "except subprocess.CalledProcessError:\n",
    "    fallback = \"https://download.pytorch.org/whl/cpu\"\n",
    "    print('PyTorch install failed, falling back to', fallback)\n",
    "    run([sys.executable, '-m', 'pip', 'install', f'--index-url={fallback}', 'torch==2.3.0', 'torchvision==0.18.0', 'torchaudio==2.3.0'])\n",
    "\n",
    "req = 'requirements-colab-gpu.txt' if has_gpu else 'requirements-colab-cpu.txt'\n",
    "run([sys.executable, '-m', 'pip', 'install', '-r', req])\n",
    "\n",
    "print('Python', sys.version)\n",
    "subprocess.run(['ffmpeg', '-version'])\n",
    "import torch, torchvision, torchaudio, soxr\n",
    "print('torch', torch.__version__)\n",
    "print('torchvision', torchvision.__version__)\n",
    "print('torchaudio', torchaudio.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "print('Resampler backend:', 'soxr', getattr(soxr, '__version__', 'unknown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Mount Google Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install helpers\n",
    "!pip install --quiet gdown\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and cache models (RVC/UVR)\n",
    "import hashlib, os, shutil, subprocess\n",
    "\n",
    "def md5(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return hashlib.md5(f.read()).hexdigest()\n",
    "\n",
    "def run(cmd):\n",
    "    print('+', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "def download(url, dest):\n",
    "    os.makedirs(os.path.dirname(dest), exist_ok=True)\n",
    "    if url.startswith('gdrive:'):\n",
    "        file_id = url.split(':', 1)[1]\n",
    "        run(['gdown', '--id', file_id, '--output', dest])\n",
    "    else:\n",
    "        run(['wget','--retry-connrefused','--waitretry=5','--read-timeout=20',\n",
    "             '--timeout=15','-t','0','-c', url, '-O', dest])\n",
    "\n",
    "MODELS = {\n",
    "    'rvc': {\n",
    "        'url': '',  # TODO: set to model URL or gdrive:file_id\n",
    "        'md5': None,\n",
    "        'drive': '/content/drive/MyDrive/models/RVC/G_8200.pth',\n",
    "        'local': '/content/models/RVC/G_8200.pth'\n",
    "    },\n",
    "    'uvr': {\n",
    "        'url': '',\n",
    "        'md5': None,\n",
    "        'drive': '/content/drive/MyDrive/models/UVR/UVR_MDX.pth',\n",
    "        'local': '/content/models/UVR/UVR_MDX.pth'\n",
    "    }\n",
    "}\n",
    "\n",
    "def ensure_model(name):\n",
    "    cfg = MODELS[name]\n",
    "    local, drive, url, md5_hash = cfg['local'], cfg['drive'], cfg['url'], cfg.get('md5')\n",
    "    if os.path.exists(local) and (not md5_hash or md5(local) == md5_hash):\n",
    "        print('Using existing local model:', local)\n",
    "        return local\n",
    "    if os.path.exists(drive):\n",
    "        print('Copying model from Drive:', drive)\n",
    "        os.makedirs(os.path.dirname(local), exist_ok=True)\n",
    "        shutil.copy2(drive, local)\n",
    "        if md5_hash and md5(local) != md5_hash:\n",
    "            raise ValueError('Checksum mismatch after copy')\n",
    "        return local\n",
    "    if not url:\n",
    "        raise ValueError(f'No URL specified for {name}')\n",
    "    print('Downloading model from', url)\n",
    "    download(url, local)\n",
    "    if md5_hash and md5(local) != md5_hash:\n",
    "        raise ValueError('Checksum mismatch after download')\n",
    "    os.makedirs(os.path.dirname(drive), exist_ok=True)\n",
    "    shutil.copy2(local, drive)\n",
    "    return local\n",
    "\n",
    "for model_name in MODELS:\n",
    "    try:\n",
    "        ensure_model(model_name)\n",
    "    except Exception as e:\n",
    "        print(f'Skipping {model_name}:', e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Upload stems to Drive\n",
    "# Upload four WAV files named vocals.wav, drums.wav, bass.wav and other.wav\n",
    "from google.colab import files\n",
    "import os\n",
    "INPUT_DIR = '/content/drive/MyDrive/AutoMix/input'  # @param {type:\"string\"}\n",
    "os.makedirs(INPUT_DIR, exist_ok=True)\n",
    "uploaded = files.upload()\n",
    "for name, data in uploaded.items():\n",
    "    with open(os.path.join(INPUT_DIR, name), 'wb') as f:\n",
    "        f.write(data)\n",
    "print('Uploaded files:', list(uploaded.keys()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Run pipeline\n",
    "import os, sys, subprocess\n",
    "INPUT_DIR = '/content/drive/MyDrive/AutoMix/input'  # @param {type:\"string\"}\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/AutoMix/output'  # @param {type:\"string\"}\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "cmd = [sys.executable, 'scripts/pipeline_gdrive.py', '--input', INPUT_DIR, '--output', OUTPUT_DIR]\n",
    "subprocess.run(cmd, check=True)\n",
    "print('Output files:', os.listdir(OUTPUT_DIR))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# @title Play mixed result\n",
    "import os\n",
    "from IPython.display import Audio\n",
    "OUTPUT_DIR = '/content/drive/MyDrive/AutoMix/output'  # @param {type:\"string\"}\n",
    "audio_path = os.path.join(OUTPUT_DIR, 'mix.wav')\n",
    "if os.path.exists(audio_path):\n",
    "    display(Audio(filename=audio_path))\n",
    "else:\n",
    "    print('mix.wav not found')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}