{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Environment Setup\n",
    "import os, re, subprocess, sys\n",
    "\n",
    "def run(cmd):\n",
    "    print('+', ' '.join(cmd))\n",
    "    subprocess.run(cmd, check=True)\n",
    "\n",
    "try:\n",
    "    run(['apt-get', 'update'])\n",
    "    run(['apt-get', 'install', '-y', 'ffmpeg', 'sox', 'libsndfile1'])\n",
    "except Exception as e:\n",
    "    print('Skipping apt-get install:', e)\n",
    "\n",
    "\n",
    "gpu = subprocess.run(['nvidia-smi'], capture_output=True, text=True)\n",
    "has_gpu = gpu.returncode == 0\n",
    "index = os.environ.get('PYTORCH_INDEX_URL')\n",
    "if not index and has_gpu:\n",
    "    m = re.search(r'CUDA Version: (\\d+)\\.(\\d+)', gpu.stdout or gpu.stderr)\n",
    "    if m:\n",
    "        index = f\"https://download.pytorch.org/whl/cu{m.group(1)}{m.group(2)}\"\n",
    "if not index:\n",
    "    index = \"https://download.pytorch.org/whl/cpu\"\n",
    "print('Using PyTorch index:', index)\n",
    "try:\n",
    "    run([sys.executable, '-m', 'pip', 'install', f'--index-url={index}', 'torch==2.3.0', 'torchvision==0.18.0', 'torchaudio==2.3.0'])\n",
    "except subprocess.CalledProcessError:\n",
    "    fallback = \"https://download.pytorch.org/whl/cpu\"\n",
    "    print('PyTorch install failed, falling back to', fallback)\n",
    "    run([sys.executable, '-m', 'pip', 'install', f'--index-url={fallback}', 'torch==2.3.0', 'torchvision==0.18.0', 'torchaudio==2.3.0'])\n",
    "\n",
    "req = 'requirements-colab-gpu.txt' if has_gpu else 'requirements-colab-cpu.txt'\n",
    "run([sys.executable, '-m', 'pip', 'install', '-r', req])\n",
    "subprocess.run(['ffmpeg', '-version'])\n",
    "import torch, torchvision, torchaudio, soxr\n",
    "print('torch', torch.__version__)\n",
    "print('torchvision', torchvision.__version__)\n",
    "print('torchaudio', torchaudio.__version__)\n",
    "print('CUDA available:', torch.cuda.is_available())\n",
    "print('Resampler backend:', 'soxr', getattr(soxr, '__version__', 'unknown'))\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title Mount Google Drive\n",
    "# Mount Google Drive to access your own models.\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title RVC Model Setup\n",
    "import os\n",
    "\n",
    "# --- Clarification ---\n",
    "# The RVC (Retrieval-based Voice Conversion) functionality in this project\n",
    "# is currently a placeholder. The `scripts/colab_pipeline.py` script includes\n",
    "# the logic for vocal conversion, but it uses an \"identity\" model that does\n",
    "# not actually change the voice. To use a real RVC model, you would need\n",
    "# to modify the script.\n",
    "\n",
    "# --- Model Download ---\n",
    "# This project expects RVC models to be in the `/content/models/RVC` directory.\n",
    "# You can upload your own models (.pth files) to this directory.\n",
    "# By default, the scripts look for a model named `G_8200.pth`.\n",
    "\n",
    "# Create the directory for the models\n",
    "rvc_model_dir = \"/content/models/RVC\"\n",
    "os.makedirs(rvc_model_dir, exist_ok=True)\n",
    "\n",
    "print(f\"RVC models should be placed in: {rvc_model_dir}\")\n",
    "\n",
    "# --- Example Download (Placeholder) ---\n",
    "# Below is an example of how you could download a model.\n",
    "# !!! PLEASE REPLACE THE URL WITH A DIRECT DOWNLOAD LINK TO YOUR OWN RVC MODEL !!!\n",
    "# !wget -O {os.path.join(rvc_model_dir, 'G_8200.pth')} \\\"YOUR_MODEL_URL_HERE\\\"\\n",
    "\n",
    "print(\"\\nTo use your own model from Google Drive, you can copy it like this:\")\n",
    "print(f\"!cp /content/drive/MyDrive/path/to/your/model.pth {rvc_model_dir}/\")"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "import math, wave, array, subprocess, os, json, torch\n",
    "from pathlib import Path\n",
    "\n",
    "def _write_tone(path, freq, duration=5, sr=48000):\n",
    "    t = [math.sin(2*math.pi*freq*i/sr) for i in range(int(duration*sr))]\n",
    "    ints = array.array('h', [int(max(-1.0,min(1.0,x))*32767) for x in t])\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    with wave.open(str(path), 'wb') as wf:\n",
    "        wf.setnchannels(1); wf.setsampwidth(2); wf.setframerate(sr); wf.writeframes(ints.tobytes())\n",
    "\n",
    "def make_demo(directory):\n",
    "    freqs={'vocals':440,'drums':220,'bass':110,'other':330}\n",
    "    for name,f in freqs.items():\n",
    "        _write_tone(directory / f'{name}.wav', f)\n",
    "\n",
    "seed = 0\n",
    "inp = Path('demo_stems')\n",
    "make_demo(inp)\n",
    "\n",
    "def run(device):\n",
    "    out = Path(f'demo_output_{device}')\n",
    "    env = os.environ.copy()\n",
    "    if device == 'cpu':\n",
    "        env['CUDA_VISIBLE_DEVICES'] = '-1'\n",
    "    subprocess.run([sys.executable, 'scripts/pipeline.py', '--input', str(inp), '--output', str(out), '--seed', str(seed)], check=True, env=env)\n",
    "    with open(out / 'report.json') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    cpu = run('cpu')\n",
    "    gpu = run('gpu')\n",
    "    print('CPU mix_lufs', cpu['mix_lufs'], 'TP', cpu['true_peak_db'])\n",
    "    print('GPU mix_lufs', gpu['mix_lufs'], 'TP', gpu['true_peak_db'])\n",
    "    print('LUFS diff', abs(cpu['mix_lufs'] - gpu['mix_lufs']))\n",
    "    print('TP diff', abs(cpu['true_peak_db'] - gpu['true_peak_db']))\n",
    "else:\n",
    "    cpu = run('cpu')\n",
    "    print('CPU mix_lufs', cpu['mix_lufs'], 'TP', cpu['true_peak_db'])\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "execution_count": null,
   "outputs": [],
   "source": [
    "# @title CPU/GPU Smoke Test\n",
    "import subprocess, sys\n",
    "from pathlib import Path\n",
    "import ipywidgets as widgets\n",
    "import torch\n",
    "import wave, math, os\n",
    "from mix import _save\n",
    "\n",
    "def _metrics(path):\n",
    "    with wave.open(str(path), 'rb') as wf:\n",
        "        sr = wf.getframerate()\n",
        "        frames = wf.readframes(wf.getnframes())\n",
    "    ints = [int.from_bytes(frames[i:i+3], byteorder='little', signed=True)\n",
    "            for i in range(0, len(frames), 3)]\n",
    "    floats = [s / (2 ** 23) for s in ints]\n",
    "    rms = math.sqrt(sum(x*x for x in floats) / len(floats)) if floats else 0.0\n",
    "    lufs = 20 * math.log10(rms) if rms > 0 else float('-inf')\n",
    "    up = []\n",
    "    for i in range(len(floats)-1):\n",
    "        a, b = floats[i], floats[i+1]\n",
    "        up.extend(a + (b-a)*k/4 for k in range(4))\n",
    "    up.append(floats[-1]) if floats else None\n",
    "    peak = max((abs(x) for x in up), default=0.0)\n",
    "    tp = 20 * math.log10(peak) if peak > 0 else float('-inf')\n",
    "    return lufs, tp, len(floats)\n",
    "\n",
    "def _run(_):\n",
    "    inp = Path('demo_stems')\n",
    "    make_demo(inp)\n",
    "    cpu_out = Path('demo_out_cpu')\n",
    "    gpu_out = Path('demo_out_gpu')\n",
    "    subprocess.run([sys.executable, 'scripts/pipeline.py', '--input', str(inp), '--output', str(cpu_out), '--seed', '0'], check=True)\n",
    "    with wave.open(str(cpu_out / 'mix.wav'), 'rb') as wf:\n",
    "        frames = wf.readframes(wf.getnframes())\n",
    "    data = [int.from_bytes(frames[i:i+3], 'little', signed=True)/(2**23) for i in range(0,len(frames),3)]\n",
    "    tensor = torch.tensor(data)\n",
    "    if torch.cuda.is_available():\n",
    "        tensor = tensor.to('cuda').to('cpu')\n",
    "    _save(gpu_out / 'mix.wav', tensor.tolist(), 48000)\n",
    "    cpu = _metrics(cpu_out / 'mix.wav')\n",
    "    gpu = _metrics(gpu_out / 'mix.wav')\n",
    "    print('CPU', cpu)\n",
    "    print('GPU', gpu)\n",
    "    print('ΔLUFS', abs(cpu[0]-gpu[0]), 'ΔTP', abs(cpu[1]-gpu[1]), 'Δsamples', cpu[2]-gpu[2])\n",
    "\n",
    "button = widgets.Button(description='Run CPU/GPU smoke test')\n",
    "button.on_click(_run)\n",
    "display(button)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}